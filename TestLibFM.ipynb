{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cf [this](https://github.com/jfloff/pywFM) github repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pywFM\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "from scipy.sparse import csr_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formatting from DataFrame to sparse matrix, the format needed for libFM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def df_to_sparse_split(path, p_test=0.1):\n",
    "    \"\"\"\n",
    "        Rewrites our matrix of user movie association in the following format, starting from a 2 column csv file with :\n",
    "        1st column : user id and movie id mixed, 2nd column : rating. The output matrix will take the form \n",
    "        \n",
    "         Users  |     Movies    \n",
    "        A  B  C | TI  NH  SW  ST\n",
    "        [1, 0, 0,  1,  0,  0,  0],\n",
    "        [1, 0, 0,  0,  1,  0,  0],\n",
    "        [1, 0, 0,  0,  0,  1,  0],\n",
    "        [0, 1, 0,  0,  0,  1,  0],\n",
    "        [0, 1, 0,  0,  0,  0,  1],\n",
    "        [0, 0, 1,  1,  0,  0,  0],\n",
    "        [0, 0, 1,  0,  0,  1,  0] \n",
    "        ])\n",
    "        \n",
    "        target = [5, 3, 1, 4, 5, 1, 5]\n",
    "        \n",
    "        @param path : The path of the training/testing data\n",
    "        @oaram p_test : The percentage of elements that should be in the training\n",
    "        @return features_te, target_te : the testing matrix and testing target values\n",
    "        @return features_tr, target_tr : the training matrix and the training target values\n",
    "    \"\"\"\n",
    "    # 1. Loading the DF and formatting it\n",
    "    df = pd.read_csv(path)\n",
    "    df['User'] = [(ID.split('_')[0])[1:] for ID in df['Id']]\n",
    "    df['Movie'] = [(ID.split('_')[1])[1:] for ID in df['Id']]\n",
    "    parsed_df = df[['User', 'Movie', 'Prediction']].astype(int)\n",
    "    parsed_df[['Id']] = df[['Id']]\n",
    "\n",
    "    parsed_df = parsed_df.sort_values(['Movie','User'],ascending=[True,True])\n",
    "    \n",
    "    user_index = np.squeeze(np.array(parsed_df['User']-1))\n",
    "    movie_index = np.squeeze(np.array(parsed_df['Movie'] + max(user_index)))\n",
    "    ratings = np.squeeze(np.array(parsed_df['Prediction']))\n",
    "    \n",
    "#2. Test train split    \n",
    "# We make no permutation if either everything is a train or a test split.\n",
    "    if p_test > 0 and p_test <1:\n",
    "        indices = np.random.permutation(np.arange(0,len(user_index)))\n",
    "    \n",
    "        idx_te = indices[0:int(len(indices)*p_test)]\n",
    "        idx_tr = indices[int(len(indices)*p_test):]\n",
    "    elif p_test == 1:\n",
    "        idx_te = np.arange(0,len(user_index))\n",
    "        idx_tr = []\n",
    "    else:\n",
    "        idx_te = []\n",
    "        idx_tr = np.arange(0,len(user_index))\n",
    "    \n",
    "    #3.Formatting now the way we need to use libFM\n",
    "    # a. Testing set\n",
    "    col_entries_te = np.r_[user_index[idx_te],movie_index[idx_te]]\n",
    "    indices_te = np.arange(0,len(user_index[idx_te]))\n",
    "    row_entries_te = np.r_[indices_te,indices_te]\n",
    "    entries_te = np.ones(len(row_entries_te))\n",
    "    \n",
    "    features_te = csr_matrix((entries_te,(row_entries_te, col_entries_te)),shape = (len(indices_te),len(col_entries_te)))\n",
    "    target_te = ratings[idx_te]\n",
    "    \n",
    "    # b. Training set\n",
    "    col_entries_tr = np.r_[user_index[idx_tr],movie_index[idx_tr]]\n",
    "    indices_tr = np.arange(0,len(user_index[idx_tr]))\n",
    "    row_entries_tr = np.r_[indices_tr,indices_tr]\n",
    "    entries_tr = np.ones(len(row_entries_tr))\n",
    "    \n",
    "    features_tr = csr_matrix((entries_tr,(row_entries_tr, col_entries_tr)),shape = (len(indices_tr),len(col_entries_tr)))\n",
    "    target_tr = ratings[idx_tr]    \n",
    "    \n",
    "    return features_te, target_te, features_tr, target_tr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of run for ALS with libFM (parameters to be tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#als\n",
    "fm = pywFM.FM(task = 'regression', learning_method='als', num_iter=5, init_stdev = 0.1, k2 = 8,\n",
    "             r0_regularization = 1.5, r1_regularization = 2, r2_regularization = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of run with MCMC (parameters to be tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#mcmc\n",
    "fm = pywFM.FM(task='regression', num_iter=500,init_stdev=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# split features and target for train/test : to be used for cross validation\n",
    "features_te, target_te, features_tr, target_tr = df_to_sparse_split(\"data_train.csv\", 0.1)\n",
    "\n",
    "model = fm.run(features_tr, target_tr, features_te, target_te)\n",
    "\n",
    "pred = model.predictions\n",
    "pred = np.round(pred)\n",
    "# you can also get the model weights\n",
    "weights = model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.rlog.rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Real run here :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "real_te_features, real_te_target, _, _ = df_to_sparse_split(\"submission.csv\",1.)\n",
    "_, _, features_tr, target_tr = df_to_sparse_split(\"data_train.csv\", 0.0)\n",
    "\n",
    "model = fm.run(features_tr, target_tr, real_te_features, real_te_target)\n",
    "pred = model.predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.rlog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_submission(submission_data_path, prediction, out_path):\n",
    "    df = pd.read_csv(submission_data_path)\n",
    "    df['User'] = [(ID.split('_')[0])[1:] for ID in df['Id']]\n",
    "    df['Movie'] = [(ID.split('_')[1])[1:] for ID in df['Id']]\n",
    "    df[['User','Movie']] = df[['User','Movie']].apply(pd.to_numeric)\n",
    "    df = df.sort_values(['Movie','User'],ascending=[True,True])\n",
    "    df['Prediction'] = prediction.astype(int)\n",
    "    \n",
    "    df[['Id','Prediction']].to_csv(out_path, index = False)\n",
    "pred = np.round(model.predictions)\n",
    "write_submission(\"submission.csv\",pred,\"thomas_submission_mcmc_std_1_iter_500.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"submission.csv\")\n",
    "df['User'] = [(ID.split('_')[0])[1:] for ID in df['Id']]\n",
    "df['Movie'] = [(ID.split('_')[1])[1:] for ID in df['Id']]\n",
    "parsed_df = df[['User', 'Movie', 'Prediction']].astype(int)\n",
    "parsed_df[['Id']] = df[['Id']]\n",
    "\n",
    "parsed_df2 = parsed_df.sort_values(['User'],ascending=True)\n",
    "parsed_df2['Prediction'] = pred.astype(int)\n",
    "parsed_df2 = parsed_df2.sort_values(['Movie','User'],ascending=[True,True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parsed_df.sort_values(['Movie'],ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "parsed_df2.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.io\n",
    "import scipy.sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from helpers import load_data, preprocess_data\n",
    "\n",
    "path_dataset = \"data_train.csv\"\n",
    "ratings = load_data(path_dataset)\n",
    "sp.find(ratings)\n",
    "print(ratings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from plots import plot_raw_data\n",
    "\n",
    "num_items_per_user, num_users_per_item = plot_raw_data(ratings)\n",
    "\n",
    "print(\"min # of items per user = {}, min # of users per item = {}.\".format(\n",
    "        min(num_items_per_user), min(num_users_per_item)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_data(ratings, num_items_per_user, num_users_per_item,\n",
    "               min_num_ratings, p_test=0.1):\n",
    "    \"\"\"split the ratings to training data and test data.\n",
    "    Args:\n",
    "        min_num_ratings: \n",
    "            all users and items we keep must have at least min_num_ratings per user and per item. \n",
    "    \"\"\"\n",
    "    # set seed\n",
    "    np.random.seed(988)\n",
    "    \n",
    "    # select user and item based on the condition.\n",
    "    valid_users = np.where(num_items_per_user >= min_num_ratings)[0]\n",
    "    valid_items = np.where(num_users_per_item >= min_num_ratings)[0]\n",
    "    valid_ratings = ratings[valid_items, :][: , valid_users]  \n",
    "    \n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # split the data and return train and test data. TODO\n",
    "    # NOTE: we only consider users and movies that have more\n",
    "    # than 10 ratings\n",
    "    # ***************************************************\n",
    "    \n",
    "    values = sp.find(valid_ratings)\n",
    "    indexUser = values[0]\n",
    "    indexItem = values[1]\n",
    "    indexRate = values[2]\n",
    "    \n",
    "    indices = np.random.permutation(len(indexUser))\n",
    "    testIndices = indices[0:p_test*len(indices)]\n",
    "    trainIndices = indices[p_test*len(indices):]\n",
    "    \n",
    "    test = sp.coo_matrix((indexRate[testIndices],\n",
    "                             (indexUser[testIndices], indexItem[testIndices])),\n",
    "                            shape = valid_ratings.shape).tocsr()\n",
    "    train = sp.coo_matrix((indexRate[trainIndices],(indexUser[trainIndices], indexItem[trainIndices])), shape = valid_ratings.shape).tocsr()\n",
    "\n",
    "    print(\"Total number of nonzero elements in original data:{v}\".format(v=ratings.nnz))\n",
    "    print(\"Total number of nonzero elements in processed data:{v}\".format(v=valid_ratings.nnz))\n",
    "    print(\"Total number of nonzero elements in train data:{v}\".format(v=train.nnz))\n",
    "    print(\"Total number of nonzero elements in test data:{v}\".format(v=test.nnz))\n",
    "    return valid_ratings, train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from plots import plot_train_test_data\n",
    "\n",
    "valid_ratings, train, test = split_data(\n",
    "    ratings, num_items_per_user, num_users_per_item, min_num_ratings=10, p_test=0.1)\n",
    "plot_train_test_data(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Baselines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "values = sp.find(ratings)\n",
    "items = values[0]\n",
    "users = values[1]\n",
    "rates = values[2]\n",
    "print(np.unique(users).shape)\n",
    "print(np.unique(items).shape)\n",
    "print(np.unique(rates).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from helpers import calculate_mse\n",
    "\n",
    "def baseline_global_mean(train, test):\n",
    "    \"\"\"baseline method: use the global mean.\"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # TODO\n",
    "    # ***************************************************    \n",
    "    mean = sp.find(train)[2].mean()\n",
    "    testRates = sp.find(test)[2]\n",
    "    return calculate_mse(testRates, mean), mean\n",
    "\n",
    "baseline_global_mean(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def baseline_user_mean(train, test):\n",
    "    \"\"\"baseline method: use the user means as the prediction.\"\"\"\n",
    "    mse = 0\n",
    "    num_items, num_users = train.shape\n",
    "    \n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # TODO\n",
    "    # ***************************************************\n",
    "    values = sp.find(train)\n",
    "    items = values[0]\n",
    "    users = values[1]\n",
    "    rates = values[2]\n",
    "    \n",
    "    values_test = sp.find(test)\n",
    "    items_test = values_test[0]\n",
    "    users_test = values_test[1]\n",
    "    rates_test = values_test[2]\n",
    "    \n",
    "    print(users)\n",
    "    print(items)\n",
    "    print(rates)\n",
    "    \n",
    "    ratePerUser = np.zeros(len(np.unique(users))) # mean rate per user (over all movies)\n",
    "    for i,user in enumerate(np.unique(users)):\n",
    "        ratePerUser[i] = np.mean(rates[users == user])\n",
    "        # ratePerUser[i] = mean rate given by user 'user' \n",
    "    \n",
    "    print(users_test.shape)\n",
    "    print(ratePerUser[users_test].shape)\n",
    "    return calculate_mse(rates_test, ratePerUser[users_test]), ratePerUser[users_test]\n",
    "\n",
    "baseline_user_mean(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v = sp.find(test)\n",
    "print(v[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The user mean method only considers the user past and looks at its mean rate, and then predicts this rate, whatever the movie is. The obtained rmse is 1.06."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def baseline_item_mean(train, test):\n",
    "    \"\"\"baseline method: use item means as the prediction.\"\"\"\n",
    "    mse = 0\n",
    "    num_items, num_users = train.shape\n",
    "    \n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # TODO\n",
    "    # ***************************************************\n",
    "    values = sp.find(train)\n",
    "    items = values[0]\n",
    "    users = values[1]\n",
    "    rates = values[2]\n",
    "    \n",
    "    values_test = sp.find(test)\n",
    "    items_test = values_test[0]\n",
    "    users_test = values_test[1]\n",
    "    rates_test = values_test[2]\n",
    "    \n",
    "    ratePerMovie = np.zeros(len(np.unique(items))) # mean rate of each movie (over all users)\n",
    "    for i,item in enumerate(np.unique(items)):\n",
    "        ratePerMovie[i] = np.mean(rates[items == item])\n",
    "    \n",
    "    return calculate_mse(rates_test, ratePerMovie[items_test]), ratePerMovie[items_test]\n",
    "    \n",
    "baseline_item_mean(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The item mean method only considers the movie past rates and looks at its mean rate, and then predicts this rate, whatever the user is. The obtained rmse is 1.18. This is worse than user mean method, which means that if we are asked to predict how user i rates movie j, it is better to look only at the rates the user gave to other movies (ie see if he usually gives high rates or not), than to only look at the rates the movie received from other users (ie see if this is a good movie or not). This fact is actually a bit strange, we would rather think that the rates most depends on whether the movie is good or not, than whether the user gives good rates or not..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mixed_method(train, test):\n",
    "    \n",
    "    (mse1, mean) = baseline_global_mean(train, test)\n",
    "    (mse2, ratesUserMean) = baseline_user_mean(train, test)\n",
    "    (mse3, ratesItemMean) = baseline_item_mean(train, test)\n",
    "    \n",
    "    w1=0\n",
    "    w2=3\n",
    "    w3=1\n",
    "    mixedRates = (w1*mean + w2*ratesUserMean + w3*ratesItemMean) / (w1+w2+w3)\n",
    "    \n",
    "    if len(values) > 2:\n",
    "        return calculate_mse(sp.find(test)[2], mixedRates), mixedRates\n",
    "    return mixedRates\n",
    "\n",
    "mixed_method(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe than by combining methods, we get a better performance than with each method separated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_path = \"sampleSubmission.csv\"\n",
    "testSet = load_data(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testSetValues = sp.find(testSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictionsTest = mixed_method(train,testSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/srv/spark')\n",
    "import pyspark\n",
    "from pyspark.mllib.recommendation import ALS, MatrixFactorizationModel, Rating\n",
    "sc = pyspark.SparkContext()\n",
    "sql_sc = pyspark.sql.SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "values_train = sp.find(train)\n",
    "trainItems = values_train[0]\n",
    "trainUsers = values_train[1]\n",
    "trainRates = values_train[2]\n",
    "\n",
    "trainFrame = pd.DataFrame()\n",
    "trainFrame['User'] = trainUsers\n",
    "trainFrame['Movie'] = trainItems\n",
    "trainFrame['Prediction'] = trainRates\n",
    "\n",
    "trainFrame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s_df_train = sql_sc.createDataFrame(trainFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(s_df_train.rdd.first())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Build the recommendation model using Alternating Least Squares\n",
    "rank = 10\n",
    "numIterations = 10\n",
    "model = ALS.train(s_df_train.rdd, rank, numIterations, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "values_test = sp.find(test)\n",
    "testItems = values_test[0]\n",
    "testUsers = values_test[1]\n",
    "testRates = values_test[2]\n",
    "\n",
    "testFrame = pd.DataFrame()\n",
    "testFrame['User'] = testUsers\n",
    "testFrame['Movie'] = testItems\n",
    "testFrame['Prediction'] = testRates\n",
    "\n",
    "testFrame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s_df_test = sql_sc.createDataFrame(testFrame)\n",
    "print(s_df_test.rdd.first())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Evaluate the model on training data\n",
    "testdata = s_df_test.rdd.map(lambda p: (p[0], p[1]))\n",
    "predictionsTest = model.predictAll(testdata.rdd).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "ratesAndPreds = s_df_test.rdd.map(lambda r: (r[0], r[1], r[2])).join(predictions)\n",
    "MSE = ratesAndPreds.map(lambda r: (r[1][0] - r[1][1])**2).mean()\n",
    "print(\"Mean Squared Error = \" + str(MSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = predictions.toDF()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(type(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictionsDF = df.toPandas()\n",
    "predictionsDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictionsDF.columns = ['User', 'Movie', 'Prediction']\n",
    "predictionsDF.head()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
